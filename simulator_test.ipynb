{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "from src.simulator import Simulator\n",
    "from src.encoder import EncoderResnet18\n",
    "import torch\n",
    "from src.agent import NCPAgent\n",
    "from src.model import Model, SequenceLearner\n",
    "\n",
    "simulator = Simulator(world_name='Town04_opt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alloc!\n",
      "Camera stream started\n"
     ]
    }
   ],
   "source": [
    "simulator.world.get_spectator().set_transform(\n",
    "    carla.Transform(\n",
    "        location=carla.Location(x=398.7934265136719,\n",
    "                                y=-56.03200912475586,\n",
    "                                z=3.37939715385437)))\n",
    "\n",
    "simulator.spawn_car_with_camera(\n",
    "    rel_coordinates=carla.Location(x=1.2, z=1.9) # camera coords\n",
    ")\n",
    "vehicle = simulator.get_vehicle()\n",
    "\n",
    "\n",
    "output_size = 2\n",
    "units = 512\n",
    "\n",
    "ncp = Model(output_size, units)\n",
    "\n",
    "agent = NCPAgent(simulator, ncp)\n",
    "\n",
    "next_waypoint  = [simulator.world.get_map().get_waypoint(vehicle.get_location(),\n",
    "                                                    project_to_road=True,\n",
    "                                                    lane_type=(carla.LaneType.Driving))]\n",
    "\n",
    "waypoints = []\n",
    "dist_between_waypoints = 20\n",
    "for _ in range(150):\n",
    "    waypoints.append(next_waypoint[-1])\n",
    "    # simulator.world.get_spectator().set_transform(next_waypoint[-1].transform)\n",
    "    next_waypoint = next_waypoint[-1].next(dist_between_waypoints)\n",
    "\n",
    "dest = waypoints[6].transform.location\n",
    "agent.set_destination(dest)\n",
    "agent.set_target_speed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_learner = SequenceLearner(ncp, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: log/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type  | Params\n",
      "--------------------------------\n",
      "0 | model | Model | 2.6 M \n",
      "--------------------------------\n",
      "2.1 M     Trainable params\n",
      "524 K     Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`train_dataloader` must be implemented to be used with the Lightning Trainer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     32\u001b[0m control, movement, raw_data \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mrun_step()\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_learner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(control\u001b[38;5;241m.\u001b[39msteer)\n\u001b[1;32m     35\u001b[0m vehicle\u001b[38;5;241m.\u001b[39mapply_control(control)\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:197\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:225\u001b[0m, in \u001b[0;36m_FitLoop.setup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: resetting train dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    224\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_source\n\u001b[0;32m--> 225\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43m_request_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataloader()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataloader, CombinedLoader):\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:342\u001b[0m, in \u001b[0;36m_request_dataloader\u001b[0;34m(data_source)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    The requested dataloader\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:306\u001b[0m, in \u001b[0;36m_DataLoaderSource.dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the dataloader from the source.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03mIf the source is a module, the method with the corresponding :attr:`name` gets called.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance, pl\u001b[38;5;241m.\u001b[39mLightningDataModule):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/mnt/hard_drive/habkaffee_part/programming/coursework/venv/lib/python3.8/site-packages/pytorch_lightning/core/hooks.py:480\u001b[0m, in \u001b[0;36mDataHooks.train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TRAIN_DATALOADERS:\n\u001b[1;32m    454\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"An iterable or collection of iterables specifying training samples.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m \n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`train_dataloader` must be implemented to be used with the Lightning Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `train_dataloader` must be implemented to be used with the Lightning Trainer"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from IPython.display import display\n",
    "import time\n",
    "import sys\n",
    "import pytorch_lightning as pl\n",
    "sys.path.append(\"CARLA_SIM/PythonAPI/carla/\")\n",
    "from agents.navigation.basic_agent import BasicAgent\n",
    "\n",
    "idx = 1\n",
    "waypoint = waypoints[idx]\n",
    "to_PIL = torchvision.transforms.ToPILImage()\n",
    "\n",
    "basic_agent = BasicAgent(vehicle=vehicle)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=pl.loggers.CSVLogger(\"log\"),\n",
    "    max_epochs=5,\n",
    "    gradient_clip_val=1, #clip grad for training stabilizing\n",
    ")\n",
    "\n",
    "while True:\n",
    "    if vehicle.get_location().distance(dest) < 0.5:\n",
    "        print(f\"Destination reached\")\n",
    "        break\n",
    "    if (vehicle.get_location().distance(waypoint.transform.location) <= dist_between_waypoints / 4) or \\\n",
    "        (vehicle.get_location().distance(waypoint.transform.location) >= dist_between_waypoints * 2 and \\\n",
    "         vehicle.get_location().distance(waypoint.transform.location) <= dist_between_waypoints * 3):\n",
    "        print(f'Waypoint {idx} was reached')\n",
    "        waypoint = waypoints[idx + 1]\n",
    "        idx += 1\n",
    "    \n",
    "    control, movement, raw_data = agent.run_step()\n",
    "    trainer.fit(seq_learner)\n",
    "    print(control.steer)\n",
    "    vehicle.apply_control(control)\n",
    "    \n",
    "    if agent.done():\n",
    "        print(\"The target has been reached, stopping the simulation\")\n",
    "        break\n",
    "vehicle.apply_control(carla.VehicleControl(throttle = 0.0, brake=1.0, steer = 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera stream stopped\n"
     ]
    }
   ],
   "source": [
    "simulator.destroy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we will save the conv layer weights in this list\n",
    "# model_weights =[]\n",
    "# #we will save the 49 conv layers in this list\n",
    "# conv_layers = []\n",
    "# # get all the model children as list\n",
    "# model_children = list(model.children())\n",
    "# #counter to keep count of the conv layers\n",
    "# counter = 0\n",
    "# #append all the conv layers and their respective wights to the list\n",
    "# for i in range(len(model_children)):\n",
    "#     if type(model_children[i]) == nn.Conv2d:\n",
    "#         counter+=1\n",
    "#         model_weights.append(model_children[i].weight)\n",
    "#         conv_layers.append(model_children[i])\n",
    "#     elif type(model_children[i]) == nn.Sequential:\n",
    "#         for j in range(len(model_children[i])):\n",
    "#             for child in model_children[i][j].children():\n",
    "#                 if type(child) == nn.Conv2d:\n",
    "#                     counter+=1\n",
    "#                     model_weights.append(child.weight)\n",
    "#                     conv_layers.append(child)\n",
    "# print(f\"Total convolution layers: {counter}\")\n",
    "# print(f\"{conv_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = transform(image)\n",
    "# image = image[:3,:,:]\n",
    "# print(f\"Image shape before: {image.shape}\")\n",
    "# image = image.unsqueeze(0)\n",
    "# print(f\"Image shape after: {image.shape}\")\n",
    "# image = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = []\n",
    "# names = []\n",
    "# for layer in conv_layers[0:]:\n",
    "#     image = layer(image)\n",
    "#     outputs.append(image)\n",
    "#     names.append(str(layer))\n",
    "# print(len(outputs))\n",
    "# # print feature_maps\n",
    "# for feature_map in outputs:\n",
    "#     print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = []\n",
    "# for feature_map in outputs:\n",
    "#     feature_map = feature_map.squeeze(0)\n",
    "#     gray_scale = torch.sum(feature_map,0)\n",
    "#     gray_scale = gray_scale / feature_map.shape[0]\n",
    "#     processed.append(gray_scale.data.cpu().numpy())\n",
    "# for fm in processed:\n",
    "#     print(fm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(30, 50))\n",
    "# for i in range(len(processed)):\n",
    "#     a = fig.add_subplot(5, 4, i+1)\n",
    "#     imgplot = plt.imshow(processed[i])\n",
    "#     a.axis(\"off\")\n",
    "#     a.set_title(names[i].split('(')[0], fontsize=30)\n",
    "# plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import pytorch_lightning as pl\n",
    "# import torch.utils.data as data\n",
    "\n",
    "# from src.model import SequenceLearner, NCP\n",
    "\n",
    "# ncp = NCP(image_features.shape[1], output_size, units)\n",
    "# ncp_model = ncp.get_ncp()\n",
    "# learner = SequenceLearner(ncp_model, lr=0.01)\n",
    "# trainer = pl.Trainer(\n",
    "#     logger=pl.loggers.CSVLogger(\"log\"),\n",
    "#     max_epochs=5,\n",
    "#     gradient_clip_val=1, #clip grad for training stabilizing\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, sys\n",
    "# sys.path.append(glob.glob('CARLA_SIM/PythonAPI/carla/'))\n",
    "sys.path.append(\"CARLA_SIM/PythonAPI/carla/\")\n",
    "from agents.navigation.basic_agent import BasicAgent\n",
    "# from agents.navigation.behavior_agent import BehaviorAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.spawn_car_with_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = simulator.get_vehicle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = BehaviorAgent(vehicle, behavior='aggressive')\n",
    "agent = BasicAgent(vehicle)\n",
    "dest = simulator.spawn_points[50].location\n",
    "agent.set_destination(dest)\n",
    "agent.follow_speed_limits(False)\n",
    "agent.set_target_speed(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    if agent.done():\n",
    "        print(\"The target has been reached, stopping the simulation\")\n",
    "        break\n",
    "    # if collided == True:\n",
    "    #     vehicle.apply_control(carla.VehicleControl(throttle = 0.0, brake=1.0, steer = 0.0))\n",
    "    #     print(\"Collision detected. Abort\")\n",
    "    #     break\n",
    "\n",
    "    vehicle.apply_control(agent.run_step())\n",
    "    # time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.destroy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
