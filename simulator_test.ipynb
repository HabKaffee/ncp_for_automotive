{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "from src.simulator import Simulator\n",
    "from src.agent import NCPAgent\n",
    "from src.model import Model, Trainer\n",
    "\n",
    "import torchvision\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "sys.path.append(\"CARLA_SIM/PythonAPI/carla/\")\n",
    "from agents.navigation.basic_agent import BasicAgent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import Model, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(world_name='Town03_opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# simulator.world.get_spectator().set_transform(\n",
    "#     carla.Transform(\n",
    "#         location=carla.Location(x=398.7934265136719,\n",
    "#                                 y=-56.03200912475586,\n",
    "#                                 z=3.37939715385437)))\n",
    "\n",
    "# simulator.spawn_car_with_camera(\n",
    "#     rel_coordinates=carla.Location(x=1.2, z=1.9) # camera coords\n",
    "# )\n",
    "# vehicle = simulator.get_vehicle()\n",
    "\n",
    "\n",
    "# output_size = 1\n",
    "# units = 19\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device)\n",
    "\n",
    "# ncp = Model(output_size, units)\n",
    "# ncp.to(device)\n",
    "# if not os.path.isdir(f'out/{simulator.world_name}'):\n",
    "#     os.mkdir(f'out/{simulator.world_name}')\n",
    "# with open(f'out/{simulator.world_name}/data.txt', 'a+') as f:\n",
    "#     f.write(f'timestamp start = {time.time()}\\n')\n",
    "# agent = NCPAgent(simulator, ncp, target_speed=10)\n",
    "\n",
    "# next_waypoint  = [simulator.world.get_map().get_waypoint(vehicle.get_location(),\n",
    "#                                                     project_to_road=True,\n",
    "#                                                     lane_type=(carla.LaneType.Driving))]\n",
    "\n",
    "# waypoints = []\n",
    "# dist_between_waypoints = 20\n",
    "# waypoint_num = 350\n",
    "# # waypoint_num = 10\n",
    "# for _ in range(waypoint_num):\n",
    "#     waypoints.append(next_waypoint[-1])\n",
    "#     # simulator.world.get_spectator().set_transform(next_waypoint[-1].transform)\n",
    "#     next_waypoint = next_waypoint[-1].next(dist_between_waypoints)\n",
    "\n",
    "# dest_idx = 2\n",
    "# dest = waypoints[dest_idx].transform.location\n",
    "# agent.set_destination(dest)\n",
    "# agent.set_target_speed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # os.rmdir('./out/')\n",
    "\n",
    "# idx = 1\n",
    "# waypoint = waypoints[idx]\n",
    "# to_PIL = torchvision.transforms.ToPILImage()\n",
    "\n",
    "# loss_func = torch.nn.functional.mse_loss\n",
    "# optimizer = torch.optim.Adam(ncp.parameters(), lr=0.001)\n",
    "\n",
    "# # basic_agent = BasicAgent(vehicle=vehicle)\n",
    "# trainer = Trainer(ncp, loss_func, optimizer)\n",
    "\n",
    "# while True:\n",
    "#     # if vehicle.get_location().distance(dest) < 0.5:\n",
    "#     #     print(f\"Destination reached\")\n",
    "#     #     break\n",
    "#     # if (vehicle.get_location().distance(waypoint.transform.location) <= dist_between_waypoints / 4) or \\\n",
    "#     #     (vehicle.get_location().distance(waypoint.transform.location) >= dist_between_waypoints * 2 and \\\n",
    "#     #      vehicle.get_location().distance(waypoint.transform.location) <= dist_between_waypoints * 3):\n",
    "#     #     print(f'Waypoint {idx} was reached')\n",
    "#     #     waypoint = waypoints[idx + 1]\n",
    "#     #     idx += 1\n",
    "    \n",
    "#     control, movement, raw_data, out_tensor = agent.run_step()\n",
    "#     # if raw_data is not None:\n",
    "#     #     trainer.train(raw_data, torch.tensor(control.steer))\n",
    "#     #     print(out_tensor)\n",
    "#     vehicle.apply_control(control)\n",
    "#     if agent.simulator.image_frame is not None:\n",
    "#         with open(f'out/{simulator.world_name}/data.txt', 'a+') as f:\n",
    "#             f.write(f'{agent.simulator.image_frame} : {control.steer}\\n')\n",
    "\n",
    "    \n",
    "#     if agent.done():\n",
    "#         if dest_idx < waypoint_num - 1:\n",
    "#             dest_idx += 10\n",
    "#             dest_idx = min(dest_idx, waypoint_num - 1)\n",
    "#             print(f'Intermediate destination reached. Moving to waypoint {dest_idx}')\n",
    "#             agent.is_done = False\n",
    "#             agent.set_destination(waypoints[dest_idx].transform.location)\n",
    "#             continue\n",
    "\n",
    "#         print(\"The target has been reached, stopping the simulation\")\n",
    "#         break\n",
    "# vehicle.apply_control(carla.VehicleControl(throttle = 0.0, brake=1.0, steer = 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator.destroy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncp.save_model(f'./model/pretrained_wp{waypoint_num}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator.destroy_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncp.load_state_dict(torch.load(f'model/pretrained_wp{waypoint_num}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ncp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_waypoint  = [simulator.world.get_map().get_waypoint(vehicle.get_location(),\n",
    "#                                                     project_to_road=True,\n",
    "#                                                     lane_type=(carla.LaneType.Driving))]\n",
    "\n",
    "# waypoints = []\n",
    "# dist_between_waypoints = 20\n",
    "# waypoint_num = 5\n",
    "# for _ in range(waypoint_num):\n",
    "#     waypoints.append(next_waypoint[-1])\n",
    "#     # simulator.world.get_spectator().set_transform(next_waypoint[-1].transform)\n",
    "#     next_waypoint = next_waypoint[-1].next(dist_between_waypoints)\n",
    "\n",
    "# dest_idx = 2\n",
    "# dest = waypoints[dest_idx].transform.location\n",
    "# agent.set_destination(dest)\n",
    "# agent.set_target_speed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 1\n",
    "# waypoint = waypoints[idx]\n",
    "# to_PIL = torchvision.transforms.ToPILImage()\n",
    "\n",
    "# loss_func = torch.nn.functional.mse_loss\n",
    "# optimizer = torch.optim.Adam(ncp.parameters(), lr=0.001)\n",
    "\n",
    "# # basic_agent = BasicAgent(vehicle=vehicle)\n",
    "# # trainer = Trainer(ncp, loss_func, optimizer)\n",
    "\n",
    "# while True:\n",
    "#     # if vehicle.get_location().distance(dest) < 0.5:\n",
    "#     #     print(f\"Destination reached\")\n",
    "#     #     break\n",
    "#     # if (vehicle.get_location().distance(waypoint.transform.location) <= dist_between_waypoints / 4) or \\\n",
    "#     #     (vehicle.get_location().distance(waypoint.transform.location) >= dist_between_waypoints * 2 and \\\n",
    "#     #      vehicle.get_location().distance(waypoint.transform.location) <= dist_between_waypoints * 3):\n",
    "#     #     print(f'Waypoint {idx} was reached')\n",
    "#     #     waypoint = waypoints[idx + 1]\n",
    "#     #     idx += 1\n",
    "    \n",
    "#     control, movement, raw_data, out_tensor = agent.run_step()\n",
    "#     # trainer.train(raw_data, torch.tensor(control.steer))\n",
    "#     print(control.steer, movement.item(), out_tensor)\n",
    "#     new_control = carla.VehicleControl(steer=movement.item(), throttle=control.throttle, brake=control.brake)\n",
    "#     vehicle.apply_control(new_control)\n",
    "    \n",
    "#     if agent.done():\n",
    "#         if dest_idx < waypoint_num - 1:\n",
    "#             dest_idx += 10\n",
    "#             dest_idx = min(dest_idx, waypoint_num - 1)\n",
    "#             print(f'Intermediate destination reached. Moving to waypoint {dest_idx}')\n",
    "#             agent.is_done = False\n",
    "#             agent.set_destination(waypoints[dest_idx].transform.location)\n",
    "#             continue\n",
    "\n",
    "#         print(\"The target has been reached, stopping the simulation\")\n",
    "#         break\n",
    "# vehicle.apply_control(carla.VehicleControl(throttle = 0.0, brake=1.0, steer = 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator.destroy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we will save the conv layer weights in this list\n",
    "# model_weights =[]\n",
    "# #we will save the 49 conv layers in this list\n",
    "# conv_layers = []\n",
    "# # get all the model children as list\n",
    "# model_children = list(model.children())\n",
    "# #counter to keep count of the conv layers\n",
    "# counter = 0\n",
    "# #append all the conv layers and their respective wights to the list\n",
    "# for i in range(len(model_children)):\n",
    "#     if type(model_children[i]) == nn.Conv2d:\n",
    "#         counter+=1\n",
    "#         model_weights.append(model_children[i].weight)\n",
    "#         conv_layers.append(model_children[i])\n",
    "#     elif type(model_children[i]) == nn.Sequential:\n",
    "#         for j in range(len(model_children[i])):\n",
    "#             for child in model_children[i][j].children():\n",
    "#                 if type(child) == nn.Conv2d:\n",
    "#                     counter+=1\n",
    "#                     model_weights.append(child.weight)\n",
    "#                     conv_layers.append(child)\n",
    "# print(f\"Total convolution layers: {counter}\")\n",
    "# print(f\"{conv_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = transform(image)\n",
    "# image = image[:3,:,:]\n",
    "# print(f\"Image shape before: {image.shape}\")\n",
    "# image = image.unsqueeze(0)\n",
    "# print(f\"Image shape after: {image.shape}\")\n",
    "# image = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = []\n",
    "# names = []\n",
    "# for layer in conv_layers[0:]:\n",
    "#     image = layer(image)\n",
    "#     outputs.append(image)\n",
    "#     names.append(str(layer))\n",
    "# print(len(outputs))\n",
    "# # print feature_maps\n",
    "# for feature_map in outputs:\n",
    "#     print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = []\n",
    "# for feature_map in outputs:\n",
    "#     feature_map = feature_map.squeeze(0)\n",
    "#     gray_scale = torch.sum(feature_map,0)\n",
    "#     gray_scale = gray_scale / feature_map.shape[0]\n",
    "#     processed.append(gray_scale.data.cpu().numpy())\n",
    "# for fm in processed:\n",
    "#     print(fm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(30, 50))\n",
    "# for i in range(len(processed)):\n",
    "#     a = fig.add_subplot(5, 4, i+1)\n",
    "#     imgplot = plt.imshow(processed[i])\n",
    "#     a.axis(\"off\")\n",
    "#     a.set_title(names[i].split('(')[0], fontsize=30)\n",
    "# plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import pytorch_lightning as pl\n",
    "# import torch.utils.data as data\n",
    "\n",
    "# from src.model import SequenceLearner, NCP\n",
    "\n",
    "# ncp = NCP(image_features.shape[1], output_size, units)\n",
    "# ncp_model = ncp.get_ncp()\n",
    "# learner = SequenceLearner(ncp_model, lr=0.01)\n",
    "# trainer = pl.Trainer(\n",
    "#     logger=pl.loggers.CSVLogger(\"log\"),\n",
    "#     max_epochs=5,\n",
    "#     gradient_clip_val=1, #clip grad for training stabilizing\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob, os, sys\n",
    "# # sys.path.append(glob.glob('CARLA_SIM/PythonAPI/carla/'))\n",
    "# sys.path.append(\"CARLA_SIM/PythonAPI/carla/\")\n",
    "# from agents.navigation.basic_agent import BasicAgent\n",
    "# # from agents.navigation.behavior_agent import BehaviorAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator.spawn_car_with_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle = simulator.get_vehicle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # agent = BehaviorAgent(vehicle, behavior='aggressive')\n",
    "# agent = BasicAgent(vehicle)\n",
    "# dest = simulator.spawn_points[50].location\n",
    "# agent.set_destination(dest)\n",
    "# agent.follow_speed_limits(False)\n",
    "# agent.set_target_speed(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# while True:\n",
    "#     if agent.done():\n",
    "#         print(\"The target has been reached, stopping the simulation\")\n",
    "#         break\n",
    "#     # if collided == True:\n",
    "#     #     vehicle.apply_control(carla.VehicleControl(throttle = 0.0, brake=1.0, steer = 0.0))\n",
    "#     #     print(\"Collision detected. Abort\")\n",
    "#     #     break\n",
    "\n",
    "#     vehicle.apply_control(agent.run_step())\n",
    "#     # time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator.destroy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alloc!\n",
      "Epoch 0\n",
      "[(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=200x78 at 0x798173D016A0>, 0.5), (<PIL.PngImagePlugin.PngImageFile image mode=RGB size=200x78 at 0x798173D014F0>, 0.2)]\n",
      "torch.Size([3, 37, 98])\n",
      "torch.Size([3, 17, 47])\n",
      "torch.Size([3, 8, 23])\n",
      "torch.Size([3, 6, 21])\n",
      "torch.Size([3, 4, 19])\n",
      "torch.Size([3, 76])\n",
      "Features extracted; goto rnn\n",
      "torch.Size([3, 10])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m ncp \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m102\u001b[39m)\n\u001b[1;32m      6\u001b[0m tr \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mncp,\n\u001b[1;32m      7\u001b[0m              loss_func\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss,\n\u001b[1;32m      8\u001b[0m              optimizer\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(ncp\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m      9\u001b[0m              annotations_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout/test_data/data.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m              img_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout/test_data/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/coursework_ncp/src/model.py:144\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 144\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m running_vlos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/programming/coursework_ncp/src/model.py:123\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[0;34m(self, epoch, logger)\u001b[0m\n\u001b[1;32m    121\u001b[0m pred_angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(image)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_angle[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 123\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_angle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_angle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/programming/coursework_ncp/venv/lib/python3.8/site-packages/torch/nn/functional.py:3355\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[1;32m   3352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3353\u001b[0m         mse_loss, (\u001b[38;5;28minput\u001b[39m, target), \u001b[38;5;28minput\u001b[39m, target, size_average\u001b[38;5;241m=\u001b[39msize_average, reduce\u001b[38;5;241m=\u001b[39mreduce, reduction\u001b[38;5;241m=\u001b[39mreduction\n\u001b[1;32m   3354\u001b[0m     )\n\u001b[0;32m-> 3355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3356\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3357\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3360\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   3361\u001b[0m     )\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.model import Trainer, Model\n",
    "\n",
    "ncp = Model(10, 102)\n",
    "\n",
    "tr = Trainer(model=ncp,\n",
    "             loss_func=torch.nn.functional.mse_loss,\n",
    "             optimizer=torch.optim.Adam(ncp.parameters(), lr=0.001),\n",
    "             annotations_file='out/test_data/data.txt',\n",
    "             img_dir='out/test_data/')\n",
    "\n",
    "tr.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
